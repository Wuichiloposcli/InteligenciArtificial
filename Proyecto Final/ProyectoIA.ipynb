{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Proyecto de Reconocimiento de Ecuaciones Manuscritas con IA",
   "id": "3872b5095aecd1dd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Introducción\n",
    "Este notebook implementa un sistema para reconocer y evaluar ecuaciones matemáticas escritas a mano a partir de imágenes, utilizando un Perceptrón Multicapa (MLP) con PyTorch."
   ],
   "id": "bed91fbe4d7db0b8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T17:57:14.257173Z",
     "start_time": "2025-05-13T17:57:05.395887Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "import time # Para medir el tiempo de las épocas\n",
    "import matplotlib.pyplot as plt # Para mostrar la imagen de prueba\n",
    "import re # Para validación de expresiones antes de eval"
   ],
   "id": "7057d36bccc35d14",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# =============================================================================\n",
    "# 1. Carga y Preprocesamiento de Imágenes (Función del usuario)\n",
    "# ============================================================================="
   ],
   "id": "a5dcf0ff7d20537f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Descripción:\n",
    "Esta sección define la función `load_images` encargada de tomar imágenes individuales de caracteres, aplicar preprocesamiento (escala de grises, inversión, umbralización, detección de contornos, recorte, redimensionamiento a 28x28 y aplanamiento) para prepararlas como entrada al modelo.\n"
   ],
   "id": "539b4d4b2732be74"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T17:57:14.294088Z",
     "start_time": "2025-05-13T17:57:14.283189Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_images(folder):\n",
    "    \"\"\"\n",
    "    Carga imágenes desde una carpeta, las preprocesa y las aplana.\n",
    "\n",
    "    Args:\n",
    "        folder (str): Ruta a la carpeta que contiene las imágenes.\n",
    "\n",
    "    Returns:\n",
    "        list: Lista de imágenes preprocesadas y aplanadas (vectores de 784).\n",
    "              Devuelve una lista vacía si hay errores o no hay imágenes.\n",
    "    \"\"\"\n",
    "    train_data = []\n",
    "    print(f\"Procesando carpeta: {folder}\") # Mensaje de depuración\n",
    "    if not os.path.isdir(folder):\n",
    "        print(f\"Error: La carpeta no existe: {folder}\")\n",
    "        return train_data\n",
    "\n",
    "    filenames = os.listdir(folder)\n",
    "    if not filenames:\n",
    "        print(f\"Advertencia: La carpeta está vacía: {folder}\")\n",
    "        return train_data\n",
    "\n",
    "    for filename in filenames:\n",
    "        # Ignorar archivos ocultos o especiales\n",
    "        if filename.startswith('.') or filename == \"_directory\":\n",
    "             continue\n",
    "\n",
    "        file_path = os.path.join(folder, filename)\n",
    "        try:\n",
    "            # Leer en escala de grises\n",
    "            image = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "            if image is None:\n",
    "                print(f\"Advertencia: No se pudo leer la imagen {filename}. Saltando.\")\n",
    "                continue\n",
    "\n",
    "            # Invertir imagen (fondo blanco, trazo negro -> fondo negro, trazo blanco)\n",
    "            image = ~image\n",
    "\n",
    "            # Umbralizar para binarizar la imagen\n",
    "            ret, thresh = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "            # Encontrar contornos\n",
    "            contours, hierarchy = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "            if not contours:\n",
    "                print(f\"Advertencia: No se encontraron contornos en {filename}. Saltando.\")\n",
    "                continue\n",
    "\n",
    "            # Encontrar el contorno con el bounding box más grande\n",
    "            max_area = 0\n",
    "            best_rect = None # (x, y, w, h)\n",
    "            for c in contours:\n",
    "                x, y, w, h = cv2.boundingRect(c)\n",
    "                area = w * h\n",
    "                if area > max_area:\n",
    "                    max_area = area\n",
    "                    best_rect = (x, y, w, h)\n",
    "\n",
    "            if best_rect is None:\n",
    "                 print(f\"Advertencia: No se encontró un contorno válido en {filename} después del filtrado inicial. Saltando.\")\n",
    "                 continue\n",
    "\n",
    "            x_max, y_max, w_max, h_max = best_rect\n",
    "\n",
    "            # Recortar usando el bounding box del contorno más grande\n",
    "            padding = 5 # Pequeño padding\n",
    "            y1 = max(0, y_max - padding)\n",
    "            y2 = min(thresh.shape[0], y_max + h_max + padding)\n",
    "            x1 = max(0, x_max - padding)\n",
    "            x2 = min(thresh.shape[1], x_max + w_max + padding)\n",
    "            im_crop = thresh[y1:y2, x1:x2]\n",
    "\n",
    "            if im_crop.size == 0:\n",
    "                print(f\"Advertencia: El recorte resultó vacío para {filename}. Saltando.\")\n",
    "                continue\n",
    "\n",
    "            # Redimensionar a 28x28\n",
    "            im_resize = cv2.resize(im_crop, (28, 28), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "            # Aplanar a 784x1 y añadir a la lista\n",
    "            im_flattened = im_resize.reshape(784) # Aplanar a (784,)\n",
    "            train_data.append(im_flattened)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error procesando el archivo {filename}: {e}\")\n",
    "\n",
    "    print(f\"Carpeta {os.path.basename(folder)}: {len(train_data)} imágenes cargadas.\")\n",
    "    return train_data"
   ],
   "id": "9c22e57725dafe45",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# =============================================================================\n",
    "# 2. Construcción del Conjunto de Datos Completo\n",
    "# ============================================================================="
   ],
   "id": "e5958119a793b1e2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Descripción:\n",
    "Aquí se define la ruta base del dataset y se itera sobre las carpetas de cada clase (dígitos y operadores). Se utiliza la función `load_images` para cargar todas las imágenes, se les asignan etiquetas numéricas (`label_map`) y se consolida todo en `all_data_list`. Finalmente, se convierten a arrays de NumPy. Se define también `idx_to_char` para la interpretación de las predicciones.\n"
   ],
   "id": "3690ebf7515cc66b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T17:57:39.842254Z",
     "start_time": "2025-05-13T17:57:14.315104Z"
    }
   },
   "cell_type": "code",
   "source": [
    "try:\n",
    "    p = 'Data/Numbers/dataset/' \n",
    "    if not os.path.isdir(p):\n",
    "        raise FileNotFoundError(f\"La ruta base del dataset '{p}' no existe. Por favor, corrígela.\")\n",
    "except NameError:\n",
    "    print(\"Error: La variable 'p' (ruta base del dataset) no está definida.\")\n",
    "    exit()\n",
    "except FileNotFoundError as e:\n",
    "    print(e)\n",
    "    exit()\n",
    "\n",
    "\n",
    "all_data_list = []\n",
    "\n",
    "# Mapeo de nombres de carpeta a etiquetas enteras (DEBE SER CONSISTENTE)\n",
    "label_map = {\n",
    "    **{str(i): i for i in range(10)}, # Dígitos 0-9\n",
    "    'add': 10, # +\n",
    "    'sub': 11, # -\n",
    "    'mul': 12, # * (asumiendo que 'mul' es para multiplicación)\n",
    "    'div': 13, # / (asumiendo que 'div' es para división)\n",
    "    'eq': 14,  # =\n",
    "    'dec': 15, # .\n",
    "    'x': 16, # Si usas x, y, z como en tu código original\n",
    "    'y': 17,\n",
    "    'z': 18,\n",
    "}\n",
    "# Ajusta NUM_CLASSES según tu mapeo final\n",
    "NUM_CLASSES = 19\n",
    "\n",
    "# Mapeo inverso para interpretar predicciones\n",
    "# Definido aquí para asegurar que esté disponible globalmente\n",
    "idx_to_char = {v: k for k, v in label_map.items()}\n",
    "# Ajustar mapeo inverso para símbolos matemáticos comunes si es necesario\n",
    "idx_to_char[10] = '+'\n",
    "idx_to_char[11] = '-'\n",
    "idx_to_char[12] = '*' # Cambiado de 'mul'\n",
    "idx_to_char[13] = '/' # Cambiado de 'div'\n",
    "idx_to_char[14] = '='\n",
    "idx_to_char[15] = '.'\n",
    "# idx_to_char[16] = '(' # Ya está correcto\n",
    "# idx_to_char[17] = ')' # Ya está correcto\n",
    "# idx_to_char[18] = 'z' # Ejemplo si tuvieras 19 clases\n",
    "\n",
    "\n",
    "print(\"Iniciando carga de datos...\")\n",
    "for folder_name, label in label_map.items():\n",
    "    folder_path = os.path.join(p, folder_name)\n",
    "    images_in_folder = load_images(folder_path)\n",
    "    for img_flat in images_in_folder:\n",
    "        all_data_list.append((img_flat, label))\n",
    "\n",
    "if not all_data_list:\n",
    "    print(\"Error: No se cargaron datos. Verifica la ruta 'p' y el contenido de las carpetas.\")\n",
    "    exit()\n",
    "\n",
    "print(f\"\\nCarga completa. Total de muestras: {len(all_data_list)}\")\n",
    "\n",
    "features_np_flat = np.array([item[0] for item in all_data_list], dtype=np.float32)\n",
    "labels_np_int = np.array([item[1] for item in all_data_list], dtype=np.int64)\n",
    "\n",
    "print(f\"Shape de Features (aplanado): {features_np_flat.shape}\")\n",
    "print(f\"Shape de Labels (entero): {labels_np_int.shape}\")"
   ],
   "id": "1000368a46aac1df",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando carga de datos...\n",
      "Procesando carpeta: Data/Numbers/dataset/0\n",
      "Carpeta 0: 595 imágenes cargadas.\n",
      "Procesando carpeta: Data/Numbers/dataset/1\n",
      "Carpeta 1: 562 imágenes cargadas.\n",
      "Procesando carpeta: Data/Numbers/dataset/2\n",
      "Carpeta 2: 433 imágenes cargadas.\n",
      "Procesando carpeta: Data/Numbers/dataset/3\n",
      "Carpeta 3: 541 imágenes cargadas.\n",
      "Procesando carpeta: Data/Numbers/dataset/4\n",
      "Carpeta 4: 526 imágenes cargadas.\n",
      "Procesando carpeta: Data/Numbers/dataset/5\n",
      "Carpeta 5: 433 imágenes cargadas.\n",
      "Procesando carpeta: Data/Numbers/dataset/6\n",
      "Carpeta 6: 581 imágenes cargadas.\n",
      "Procesando carpeta: Data/Numbers/dataset/7\n",
      "Carpeta 7: 533 imágenes cargadas.\n",
      "Procesando carpeta: Data/Numbers/dataset/8\n",
      "Carpeta 8: 554 imágenes cargadas.\n",
      "Procesando carpeta: Data/Numbers/dataset/9\n",
      "Carpeta 9: 546 imágenes cargadas.\n",
      "Procesando carpeta: Data/Numbers/dataset/add\n",
      "Carpeta add: 596 imágenes cargadas.\n",
      "Procesando carpeta: Data/Numbers/dataset/sub\n",
      "Carpeta sub: 655 imágenes cargadas.\n",
      "Procesando carpeta: Data/Numbers/dataset/mul\n",
      "Carpeta mul: 577 imágenes cargadas.\n",
      "Procesando carpeta: Data/Numbers/dataset/div\n",
      "Carpeta div: 618 imágenes cargadas.\n",
      "Procesando carpeta: Data/Numbers/dataset/eq\n",
      "Carpeta eq: 634 imágenes cargadas.\n",
      "Procesando carpeta: Data/Numbers/dataset/dec\n",
      "Carpeta dec: 624 imágenes cargadas.\n",
      "Procesando carpeta: Data/Numbers/dataset/x\n",
      "Carpeta x: 452 imágenes cargadas.\n",
      "Procesando carpeta: Data/Numbers/dataset/y\n",
      "Carpeta y: 399 imágenes cargadas.\n",
      "Procesando carpeta: Data/Numbers/dataset/z\n",
      "Carpeta z: 212 imágenes cargadas.\n",
      "\n",
      "Carga completa. Total de muestras: 10071\n",
      "Shape de Features (aplanado): (10071, 784)\n",
      "Shape de Labels (entero): (10071,)\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# =============================================================================\n",
    "# 3. Cálculo de Mean/Std y Normalización (Variables Globales)\n",
    "# ============================================================================="
   ],
   "id": "df4fc252846032fb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Descripción:\n",
    " Se calculan la media y la desviación estándar de los píxeles de todas las imágenes del conjunto de datos. Estos valores son cruciales para la normalización Z-score que se aplicará a los datos antes de entrenar el modelo y al preprocesar nuevas imágenes para predicción. Las imágenes se normalizan inicialmente a una escala de [0,1].\n"
   ],
   "id": "9544b25318a6ce3e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T17:57:41.367613Z",
     "start_time": "2025-05-13T17:57:41.124316Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Estas variables (mean, std) son necesarias para preprocesar nuevas imágenes\n",
    "mean_pixel = np.mean(features_np_flat)\n",
    "std_pixel = np.std(features_np_flat)\n",
    "features_normalized_01 = features_np_flat / 255.0\n",
    "mean = np.mean(features_normalized_01) # Media global [0,1]\n",
    "std = np.std(features_normalized_01)   # Std global [0,1]\n",
    "if std < 1e-6: std = 1.0\n",
    "\n",
    "print(f\"\\nEstadísticas calculadas (usadas para normalización):\")\n",
    "print(f\"  Mean (0-1 scale): {mean:.4f}\")\n",
    "print(f\"  Std Dev (0-1 scale): {std:.4f}\")"
   ],
   "id": "f0f7cfe85466329f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Estadísticas calculadas (usadas para normalización):\n",
      "  Mean (0-1 scale): 0.2147\n",
      "  Std Dev (0-1 scale): 0.3798\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# =============================================================================\n",
    "# 4. Preparación para PyTorch (Tensores, Dataset, DataLoader)\n",
    "# ============================================================================="
   ],
   "id": "7e95536270e9debe"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Descripción:\n",
    "Los arrays de NumPy (características y etiquetas) se convierten a tensores de PyTorch. Las características se normalizan utilizando la media y desviación estándar calculadas previamente. Se crea un `TensorDataset` y se divide en conjuntos de entrenamiento y validación. Finalmente, se preparan los `DataLoader` para iterar sobre los datos en batches durante el entrenamiento y la evaluación.\n"
   ],
   "id": "625bb4a008d84422"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T17:57:41.666974Z",
     "start_time": "2025-05-13T17:57:41.541402Z"
    }
   },
   "cell_type": "code",
   "source": [
    "features_tensor = torch.tensor(features_np_flat, dtype=torch.float32)\n",
    "labels_tensor = torch.tensor(labels_np_int, dtype=torch.long)\n",
    "\n",
    "features_tensor = (features_tensor / 255.0 - mean) / std\n",
    "\n",
    "print(f\"\\nShapes de Tensores:\")\n",
    "print(f\"  Features Tensor: {features_tensor.shape}\")\n",
    "print(f\"  Labels Tensor: {labels_tensor.shape}\")\n",
    "\n",
    "full_dataset = TensorDataset(features_tensor, labels_tensor)\n",
    "\n",
    "# División Train/Valid\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "valid_size = len(full_dataset) - train_size\n",
    "valid_dataset = None\n",
    "if train_size > 0 and valid_size > 0:\n",
    "    train_dataset, valid_dataset = random_split(full_dataset, [train_size, valid_size])\n",
    "    print(f'\\nDivisión del Dataset:')\n",
    "    print(f'  Num Train: {len(train_dataset)}')\n",
    "    print(f'  Num Valid: {len(valid_dataset)}')\n",
    "elif len(full_dataset) > 0:\n",
    "     print('\\nDataset demasiado pequeño para dividir. Usando todo para entrenamiento.')\n",
    "     train_dataset = full_dataset\n",
    "else:\n",
    "    print(\"Error: Dataset vacío después de cargar datos.\")\n",
    "    exit()\n",
    "\n",
    "\n",
    "# DataLoaders\n",
    "BATCH_SIZE = 64\n",
    "train_iterator = DataLoader(train_dataset, shuffle=True, batch_size=BATCH_SIZE)\n",
    "valid_iterator = DataLoader(valid_dataset, batch_size=BATCH_SIZE) if valid_dataset else None\n",
    "\n",
    "print(f\"DataLoaders creados con Batch Size: {BATCH_SIZE}\")\n",
    "if not valid_iterator: print(\"Advertencia: No se creó DataLoader de validación.\")"
   ],
   "id": "b1b0c4f94b28b79",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shapes de Tensores:\n",
      "  Features Tensor: torch.Size([10071, 784])\n",
      "  Labels Tensor: torch.Size([10071])\n",
      "\n",
      "División del Dataset:\n",
      "  Num Train: 8056\n",
      "  Num Valid: 2015\n",
      "DataLoaders creados con Batch Size: 64\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# =============================================================================\n",
    "# 5. Definición del Modelo MLP (Adaptado)\n",
    "# ============================================================================="
   ],
   "id": "7e47b779022d3538"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Descripción:\n",
    "Se define la arquitectura de la red neuronal (MLP). Consiste en una capa de entrada, una capa oculta con activación ReLU, y una capa de salida para la clasificación de los caracteres. Se calcula e imprime el número total de parámetros entrenables del modelo.\n"
   ],
   "id": "4845bab802993e8b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T17:57:41.953646Z",
     "start_time": "2025-05-13T17:57:41.919006Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.input_fc = nn.Linear(input_dim, 250)\n",
    "        self.hidden_fc = nn.Linear(250, 100)\n",
    "        self.output_fc = nn.Linear(100, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h_1 = F.relu(self.input_fc(x))\n",
    "        h_2 = F.relu(self.hidden_fc(h_1))\n",
    "        y_pred = self.output_fc(h_2)\n",
    "        return y_pred\n",
    "\n",
    "INPUT_DIM = 28 * 28\n",
    "OUTPUT_DIM = NUM_CLASSES\n",
    "model = MLP(INPUT_DIM, OUTPUT_DIM)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'\\nEl modelo MLP tiene {count_parameters(model):,} parámetros entrenables.')"
   ],
   "id": "5fef9c742319c3ea",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "El modelo MLP tiene 223,269 parámetros entrenables.\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# =============================================================================\n",
    "# 6. Configuración del Entrenamiento (Optimizador, Pérdida, Dispositivo)\n",
    "# ============================================================================="
   ],
   "id": "e009428663e2f5fe"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Descripción:\n",
    "Se configura el proceso de entrenamiento: se elige el optimizador (Adam), la función de pérdida (CrossEntropyLoss, adecuada para clasificación multiclase) y se determina el dispositivo de cómputo (CPU o GPU si está disponible). El modelo y la función de pérdida se mueven al dispositivo seleccionado.\n"
   ],
   "id": "e0a1cd81fb587378"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T17:57:45.413706Z",
     "start_time": "2025-05-13T17:57:42.029005Z"
    }
   },
   "cell_type": "code",
   "source": [
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "print(f\"Entrenamiento configurado en dispositivo: {device}\")"
   ],
   "id": "4ad31c9c2fb365be",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenamiento configurado en dispositivo: cpu\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# =============================================================================\n",
    "# 7. Funciones Auxiliares de Entrenamiento y Evaluación (del Notebook)\n",
    "# ============================================================================="
   ],
   "id": "c33bc0bbeef0b269"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Descripción:\n",
    " Se definen funciones clave para el ciclo de entrenamiento:\n",
    " - `calculate_accuracy`: Calcula la precisión de las predicciones.\n",
    " - `train`: Realiza una época de entrenamiento sobre el conjunto de datos, actualizando los pesos del modelo.\n",
    " - `evaluate`: Evalúa el rendimiento del modelo sobre un conjunto de datos (generalmente validación o prueba) sin actualizar los pesos.\n",
    " - `epoch_time`: Calcula el tiempo transcurrido por época.\n"
   ],
   "id": "c348c79090c8452a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T17:57:45.521431Z",
     "start_time": "2025-05-13T17:57:45.498245Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calculate_accuracy(y_pred, y):\n",
    "    top_pred = y_pred.argmax(1, keepdim=True)\n",
    "    correct = top_pred.eq(y.view_as(top_pred)).sum()\n",
    "    acc = correct.float() / y.shape[0]\n",
    "    return acc\n",
    "\n",
    "def train(model, iterator, optimizer, criterion, device):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    model.train()\n",
    "    len_iterator = len(iterator)\n",
    "    if len_iterator == 0: return 0.0, 0.0\n",
    "    for (x, y) in iterator:\n",
    "        x = x.to(device); y = y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(x)\n",
    "        loss = criterion(y_pred, y)\n",
    "        acc = calculate_accuracy(y_pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item(); epoch_acc += acc.item()\n",
    "    return epoch_loss / len_iterator, epoch_acc / len_iterator\n",
    "\n",
    "def evaluate(model, iterator, criterion, device):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    model.eval()\n",
    "    if iterator is None: return 0.0, 0.0\n",
    "    len_iterator = len(iterator)\n",
    "    if len_iterator == 0: return 0.0, 0.0\n",
    "    with torch.no_grad():\n",
    "        for (x, y) in iterator:\n",
    "            x = x.to(device); y = y.to(device)\n",
    "            y_pred = model(x)\n",
    "            loss = criterion(y_pred, y)\n",
    "            acc = calculate_accuracy(y_pred, y)\n",
    "            epoch_loss += loss.item(); epoch_acc += acc.item()\n",
    "    return epoch_loss / len_iterator, epoch_acc / len_iterator\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ],
   "id": "2bae28d586d0303c",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# =============================================================================\n",
    "# 8. Bucle Principal de Entrenamiento\n",
    "# ============================================================================="
   ],
   "id": "c5a49c2fe33377a5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Descripción:\n",
    "Este es el bucle donde se entrena el modelo durante un número definido de épocas (`EPOCHS`). En cada época, se entrena el modelo y se evalúa en el conjunto de validación. Se guarda el modelo que obtenga la menor pérdida de validación (`best_valid_loss`) en el archivo `mlp_custom_data_model1.pt`. Se imprime el progreso (pérdida y precisión) por época.\n"
   ],
   "id": "30f80e742e924903"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T17:57:45.579499Z",
     "start_time": "2025-05-13T17:57:45.563760Z"
    }
   },
   "cell_type": "code",
   "source": [
    "EPOCHS = 15 # Reducido para pruebas rápidas, ajustar según sea necesario\n",
    "best_valid_loss = float('inf')\n",
    "model_save_path = 'mlp_custom_data_model1.pt'\n",
    "# --- Omitir entrenamiento si el modelo ya existe ---\n",
    "if os.path.exists(model_save_path):\n",
    "    print(f\"\\nEl archivo del modelo '{model_save_path}' ya existe. Saltando entrenamiento.\")\n",
    "else:\n",
    "    print(\"\\nIniciando entrenamiento...\")\n",
    "    for epoch in range(EPOCHS):\n",
    "        start_time = time.time()\n",
    "        train_loss, train_acc = train(model, train_iterator, optimizer, criterion, device)\n",
    "        valid_loss, valid_acc = evaluate(model, valid_iterator, criterion, device) if valid_iterator else (0.0, 0.0)\n",
    "        end_time = time.time()\n",
    "        epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "        save_model = False\n",
    "        if valid_iterator:\n",
    "            if valid_loss < best_valid_loss:\n",
    "                best_valid_loss = valid_loss\n",
    "                save_model = True\n",
    "        elif epoch == EPOCHS - 1:\n",
    "             print(\"\\nAdvertencia: No hay datos de validación. Guardando el modelo de la última época.\")\n",
    "             save_model = True\n",
    "        if save_model:\n",
    "            torch.save(model.state_dict(), model_save_path)\n",
    "            if valid_iterator: print(f\"\\tMejor modelo (valid loss) guardado en {model_save_path}\")\n",
    "            else: print(f\"\\tÚltimo modelo guardado en {model_save_path}\")\n",
    "        print(f'Epoch: {epoch+1:02}/{EPOCHS} | Tiempo: {epoch_mins}m {epoch_secs}s')\n",
    "        print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "        if valid_iterator: print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\n",
    "        else: print('\\t (Sin datos de validación para evaluar)')\n",
    "    # Asegurarse de que el modelo se guarde si no hubo validación\n",
    "    if not os.path.exists(model_save_path) and not valid_iterator and EPOCHS > 0:\n",
    "         torch.save(model.state_dict(), model_save_path)\n",
    "         print(f\"\\nModelo final guardado en {model_save_path} (sin validación).\")\n",
    "    print(\"\\nEntrenamiento finalizado.\")\n",
    "\n",
    "if os.path.exists(model_save_path): print(f\"El modelo se guardó en: {model_save_path}\")\n",
    "else: print(\"Advertencia: No se guardó ningún modelo.\")"
   ],
   "id": "49a14f61ce738b78",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "El archivo del modelo 'mlp_custom_data_model1.pt' ya existe. Saltando entrenamiento.\n",
      "El modelo se guardó en: mlp_custom_data_model1.pt\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# =============================================================================\n",
    "# 9. Cargar el mejor modelo y evaluar en el conjunto de validación\n",
    "# ============================================================================="
   ],
   "id": "d44a024f05adb35b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Descripción:\n",
    " Después del entrenamiento (o si se omite porque el modelo ya existe), esta sección carga los pesos del mejor modelo guardado (`mlp_custom_data_model1.pt`) en una nueva instancia de la arquitectura MLP. Luego, se evalúa este modelo cargado en el conjunto de validación para verificar su rendimiento final.\n"
   ],
   "id": "8ae2a53eaee0edbd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T17:57:45.718806Z",
     "start_time": "2025-05-13T17:57:45.607678Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"\\nIntentando cargar y evaluar el modelo desde: {model_save_path}\")\n",
    "loaded_model = None # Inicializar\n",
    "if os.path.exists(model_save_path):\n",
    "    # Crear una instancia de la MISMA arquitectura\n",
    "    loaded_model = MLP(INPUT_DIM, OUTPUT_DIM)\n",
    "    try:\n",
    "        # Cargar los pesos guardados (state_dict)\n",
    "        loaded_model.load_state_dict(torch.load(model_save_path, map_location=device))\n",
    "        print(f\"State dict cargado correctamente desde {model_save_path}\")\n",
    "        loaded_model = loaded_model.to(device) # Mover al dispositivo\n",
    "        loaded_model.eval() # Poner en modo evaluación (IMPORTANTE)\n",
    "        print(\"Modelo cargado y puesto en modo evaluación (model.eval())\")\n",
    "\n",
    "        # Evaluar en el conjunto de validación (si existe)\n",
    "        if valid_iterator:\n",
    "            print(\"\\nEvaluando el modelo cargado en el conjunto de validación...\")\n",
    "            final_valid_loss, final_valid_acc = evaluate(loaded_model, valid_iterator, criterion, device)\n",
    "            print(f'Resultado de la evaluación:')\n",
    "            print(f'\\tLoss: {final_valid_loss:.3f} | Acc: {final_valid_acc*100:.2f}%')\n",
    "        else:\n",
    "            print(\"No hay conjunto de validación para evaluar el modelo cargado.\")\n",
    "    except Exception as e:\n",
    "         print(f\"Error al cargar el state_dict o evaluar el modelo desde '{model_save_path}': {e}\")\n",
    "         loaded_model = None # Indicar que la carga falló\n",
    "else:\n",
    "    print(f\"Advertencia: No se encontró el archivo del modelo guardado '{model_save_path}'. No se pudo cargar ni evaluar.\")"
   ],
   "id": "85c3ea9538ff7db7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Intentando cargar y evaluar el modelo desde: mlp_custom_data_model1.pt\n",
      "State dict cargado correctamente desde mlp_custom_data_model1.pt\n",
      "Modelo cargado y puesto en modo evaluación (model.eval())\n",
      "\n",
      "Evaluando el modelo cargado en el conjunto de validación...\n",
      "Resultado de la evaluación:\n",
      "\tLoss: 0.186 | Acc: 93.50%\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# =============================================================================\n",
    "# 10. Probar el modelo cargado con una imagen (Lógica de Usuario Adaptada)\n",
    "# ============================================================================="
   ],
   "id": "58a63b52cf897adc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Descripción:\n",
    "Se define la función `predict_equation_from_image`. Esta función toma la ruta de una imagen que contiene una ecuación completa, la preprocesa, segmenta los caracteres individuales, filtra contornos anidados o solapados, y utiliza el modelo MLP cargado para predecir cada carácter. Finalmente, reconstruye la cadena de la ecuación y la evalúa matemáticamente. También incluye la visualización de los caracteres segmentados y sus predicciones.\n"
   ],
   "id": "87c160a84c07815"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T17:57:45.777781Z",
     "start_time": "2025-05-13T17:57:45.742777Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def predict_equation_from_image(image_path, model_to_use, device, target_mean, target_std, idx_to_char_map):\n",
    "    \"\"\"\n",
    "    Procesa una imagen que contiene una secuencia de caracteres, predice cada\n",
    "    carácter usando el modelo MLP cargado, construye la ecuación y la evalúa.\n",
    "\n",
    "    Args:\n",
    "        image_path (str): Ruta a la imagen a procesar.\n",
    "        model_to_use (torch.nn.Module): El modelo MLP cargado y en modo eval.\n",
    "        device (torch.device): Dispositivo ('cuda' o 'cpu').\n",
    "        target_mean (float): Media usada para normalizar ([0,1] scale).\n",
    "        target_std (float): Desviación estándar usada para normalizar ([0,1] scale).\n",
    "        idx_to_char_map (dict): Mapeo de índice de clase a carácter.\n",
    "\n",
    "    Returns:\n",
    "        str: La ecuación reconocida.\n",
    "        float or str: El resultado de la evaluación o un mensaje de error.\n",
    "    \"\"\"\n",
    "    # Verificar si el mapeo existe antes de usarlo dentro de la función\n",
    "    if idx_to_char_map is None:\n",
    "        print(\"Error interno: El mapeo idx_to_char_map no fue proporcionado a la función.\")\n",
    "        return \"Error Mapeo\", \"Error\"\n",
    "\n",
    "    try:\n",
    "        # --- 1. Cargar y Preprocesar Imagen (OpenCV) ---\n",
    "        img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if img is None:\n",
    "            print(f\"Error: No se pudo leer la imagen en {image_path}\")\n",
    "            return \"Error de lectura\", \"Error\"\n",
    "\n",
    "        original_img_for_display = img.copy() # Para visualización\n",
    "\n",
    "        img = ~img # Invertir\n",
    "        _, thresh = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY) # Umbralizar\n",
    "        ctrs, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE) # Contornos\n",
    "\n",
    "        if not ctrs:\n",
    "            print(\"No se encontraron contornos en la imagen.\")\n",
    "            return \"Sin contornos\", \"Error\"\n",
    "\n",
    "        # Ordenar contornos por posición x\n",
    "        cnt = sorted(ctrs, key=lambda ctr: cv2.boundingRect(ctr)[0])\n",
    "        print(f\"Contornos encontrados y ordenados: {len(cnt)}\")\n",
    "\n",
    "        # --- 2. Filtrar Contornos Anidados (Lógica del usuario) ---\n",
    "        rects = [cv2.boundingRect(c) for c in cnt] # Obtener bounding boxes (x, y, w, h)\n",
    "\n",
    "        bool_rect = []\n",
    "        for r in rects:\n",
    "            l = []\n",
    "            for rec in rects:\n",
    "                flag = 0\n",
    "                if rec != r:\n",
    "                    # Comprobar si hay solapamiento significativo (ajustar el +10 si es necesario)\n",
    "                    x1_r, y1_r, w_r, h_r = r\n",
    "                    x2_r, y2_r = x1_r + w_r, y1_r + h_r\n",
    "                    x1_rec, y1_rec, w_rec, h_rec = rec\n",
    "                    x2_rec, y2_rec = x1_rec + w_rec, y1_rec + h_rec\n",
    "\n",
    "                    # Chequear si un rectángulo está *dentro* de otro (más robusto para anidamiento)\n",
    "                    r_inside_rec = (x1_r >= x1_rec) and (y1_r >= y1_rec) and (x2_r <= x2_rec) and (y2_r <= y2_rec)\n",
    "                    rec_inside_r = (x1_rec >= x1_r) and (y1_rec >= y1_r) and (x2_rec <= x2_r) and (y2_rec <= y2_r)\n",
    "\n",
    "                    if r_inside_rec or rec_inside_r:\n",
    "                         flag = 1\n",
    "                l.append(flag)\n",
    "            bool_rect.append(l)\n",
    "\n",
    "        dump_rect = []\n",
    "        for i in range(len(cnt)):\n",
    "            for j in range(len(cnt)):\n",
    "                if bool_rect[i][j] == 1: # Si hay anidamiento/solapamiento\n",
    "                    area1 = rects[i][2] * rects[i][3]\n",
    "                    area2 = rects[j][2] * rects[j][3]\n",
    "                    # Marcar el rectángulo más pequeño para eliminar\n",
    "                    if area1 <= area2: # Incluir igualdad para eliminar uno si son idénticos\n",
    "                        if list(rects[i]) not in dump_rect: dump_rect.append(list(rects[i]))\n",
    "                    else:\n",
    "                         if list(rects[j]) not in dump_rect: dump_rect.append(list(rects[j]))\n",
    "\n",
    "\n",
    "        # Eliminar duplicados de dump_rect (ya se hace en la línea anterior)\n",
    "        # dump_rect_unique = [list(item) for item in set(tuple(row) for row in dump_rect)] # No es necesario si se añade con if not in\n",
    "        print(f\"Rectángulos marcados para eliminar (anidados/solapados): {len(dump_rect)}\")\n",
    "\n",
    "        # Obtener los rectángulos finales\n",
    "        final_rect = [r for r in rects if list(r) not in dump_rect]\n",
    "        print(f\"Rectángulos finales después del filtrado: {len(final_rect)}\")\n",
    "        # Ordenar rectángulos finales por 'x' de nuevo, por si acaso\n",
    "        final_rect.sort(key=lambda r: r[0])\n",
    "\n",
    "        # --- 3. Procesar y Predecir cada Carácter Final ---\n",
    "        processed_chars_tensors = [] # Almacenará los tensores listos para el modelo\n",
    "        processed_chars_imgs = [] # Almacenará imágenes 28x28 para visualización\n",
    "\n",
    "        for r in final_rect:\n",
    "            x, y, w, h = r\n",
    "            # Añadir padding al recortar (con cuidado de no salirse)\n",
    "            pad = 10\n",
    "            y1 = max(0, y - pad); y2 = min(thresh.shape[0], y + h + pad)\n",
    "            x1 = max(0, x - pad); x2 = min(thresh.shape[1], x + w + pad)\n",
    "            im_crop = thresh[y1:y2, x1:x2]\n",
    "\n",
    "            if im_crop.size == 0:\n",
    "                print(f\"Advertencia: Recorte vacío para rect {r}. Saltando.\")\n",
    "                continue\n",
    "\n",
    "            # Redimensionar a 28x28\n",
    "            im_resize = cv2.resize(im_crop, (28, 28), interpolation=cv2.INTER_AREA)\n",
    "            processed_chars_imgs.append(im_resize) # Guardar para mostrar\n",
    "\n",
    "            # Aplanar y asegurar tipo float32\n",
    "            im_flattened = im_resize.reshape(784).astype(np.float32)\n",
    "\n",
    "            # Convertir a Tensor\n",
    "            char_tensor = torch.tensor(im_flattened, dtype=torch.float32)\n",
    "\n",
    "            # Normalizar (usando mean/std globales)\n",
    "            # Asegurarse de que std no sea cero\n",
    "            safe_std = target_std if target_std > 1e-6 else 1.0\n",
    "            char_tensor = (char_tensor / 255.0 - target_mean) / safe_std\n",
    "\n",
    "            # Añadir dimensión de batch y mover al dispositivo\n",
    "            char_tensor = char_tensor.unsqueeze(0).to(device) # Shape: [1, 784]\n",
    "            processed_chars_tensors.append(char_tensor)\n",
    "\n",
    "        if not processed_chars_tensors:\n",
    "            print(\"No se pudieron procesar caracteres válidos después del filtrado.\")\n",
    "            return \"Sin caracteres válidos\", \"Error\"\n",
    "\n",
    "        # --- 4. Realizar Predicciones y Construir Ecuación ---\n",
    "        equation = ''\n",
    "        confidences = []\n",
    "        predicted_indices = []\n",
    "\n",
    "        model_to_use.eval() # Asegurarse de que esté en modo evaluación\n",
    "        with torch.no_grad():\n",
    "            for char_tensor in processed_chars_tensors:\n",
    "                prediction_logits = model_to_use(char_tensor)\n",
    "                probabilities = F.softmax(prediction_logits, dim=1)\n",
    "                confidence, predicted_idx = torch.max(probabilities, 1)\n",
    "\n",
    "                predicted_idx_item = predicted_idx.item()\n",
    "                predicted_indices.append(predicted_idx_item)\n",
    "                confidences.append(confidence.item())\n",
    "\n",
    "                # Construir la ecuación usando el mapeo\n",
    "                char = idx_to_char_map.get(predicted_idx_item, '?') # Usar '?' si el índice no está mapeado\n",
    "                equation += char\n",
    "                print(f\"  Predicción: Índice={predicted_idx_item}, Carácter='{char}', Confianza={confidence.item()*100:.1f}%\")\n",
    "\n",
    "        print(f\"\\nEcuación Reconocida: {equation}\")\n",
    "\n",
    "        # --- 5. Evaluar la Ecuación ---\n",
    "        result = \"No evaluable\"\n",
    "        try:\n",
    "            # Validar un poco la expresión antes de usar eval\n",
    "            # Permitir números, operadores +, -, *, /, ., (, ) y espacios\n",
    "            # Mejorar regex para permitir números decimales y negativos al inicio\n",
    "            # Quitar espacios ANTES de validar con regex y evaluar\n",
    "            cleaned_equation_for_eval = equation.replace(' ', '')\n",
    "            if re.fullmatch(r\"^[()]*([-+]?([0-9]*\\.?[0-9]+|[0-9]+\\.?[0-9]*)[()]*[+\\-*/]?)+$\", cleaned_equation_for_eval):\n",
    "                 # ¡PRECAUCIÓN! eval() puede ser inseguro. Usar con cuidado.\n",
    "                 result = eval(cleaned_equation_for_eval)\n",
    "                 print(f\"Resultado de la evaluación: {result}\")\n",
    "            else:\n",
    "                 # Intentar una limpieza básica (ej. quitar '=') si existe y no es evaluable\n",
    "                 cleaned_equation_no_equals = cleaned_equation_for_eval.rstrip('=')\n",
    "                 if cleaned_equation_no_equals != cleaned_equation_for_eval and re.fullmatch(r\"^[()]*([-+]?([0-9]*\\.?[0-9]+|[0-9]+\\.?[0-9]*)[()]*[+\\-*/]?)+$\", cleaned_equation_no_equals):\n",
    "                     print(f\"Intentando evaluar versión limpiada (sin '=' al final): {cleaned_equation_no_equals}\")\n",
    "                     result = eval(cleaned_equation_no_equals)\n",
    "                     print(f\"Resultado de la evaluación (limpiada): {result}\")\n",
    "                 else:\n",
    "                     result = \"Expresión no válida\"\n",
    "                     print(f\"La expresión '{equation}' (limpiada: '{cleaned_equation_for_eval}') no parece válida para evaluar.\")\n",
    "\n",
    "\n",
    "        except ZeroDivisionError:\n",
    "            result = \"Error: División por cero\"\n",
    "            print(result)\n",
    "        except SyntaxError as e:\n",
    "            result = f\"Error de sintaxis: {e}\"\n",
    "            print(result)\n",
    "        except Exception as e:\n",
    "            result = f\"Error durante evaluación: {e}\"\n",
    "            print(result)\n",
    "\n",
    "        # --- 6. Visualización (Opcional) ---\n",
    "        try:\n",
    "            num_chars = len(processed_chars_imgs)\n",
    "            if num_chars > 0:\n",
    "                 cols = min(num_chars, 8)\n",
    "                 rows = (num_chars + cols - 1) // cols\n",
    "                 fig, axs = plt.subplots(rows, cols, figsize=(cols * 1.5, rows * 2.5)) # Aumentar altura\n",
    "                 if rows == 1 and cols == 1: # Caso de un solo subplot\n",
    "                     axs = np.array([axs])\n",
    "                 axs = axs.flatten()\n",
    "\n",
    "                 for i in range(num_chars):\n",
    "                     axs[i].imshow(processed_chars_imgs[i], cmap='gray')\n",
    "                     pred_char = idx_to_char_map.get(predicted_indices[i], '?')\n",
    "                     conf = confidences[i] * 100\n",
    "                     axs[i].set_title(f\"'{pred_char}'\\n({conf:.0f}%)\") # Título en dos líneas\n",
    "                     axs[i].axis('off')\n",
    "\n",
    "                 for j in range(num_chars, len(axs)):\n",
    "                     axs[j].axis('off')\n",
    "\n",
    "                 fig.suptitle(f\"Predicciones Carácter por Carácter\\nEcuación: {equation}\\nResultado: {result}\", fontsize=12)\n",
    "                 plt.tight_layout(rect=[0, 0.03, 1, 0.92]) # Ajustar para título más largo\n",
    "                 plt.show()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"No se pudo mostrar la visualización de caracteres: {e}\")\n",
    "\n",
    "\n",
    "        return equation, result\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error general en predict_equation_from_image: {e}\")\n",
    "        return \"Error general\", \"Error\""
   ],
   "id": "3c70053af394930c",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T17:57:45.836674Z",
     "start_time": "2025-05-13T17:57:45.799764Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def predict_equation_from_image(image_path, model_to_use, device, target_mean, target_std, idx_to_char_map):\n",
    "    \"\"\"\n",
    "    Procesa una imagen que contiene una secuencia de caracteres, predice cada\n",
    "    carácter usando el modelo MLP cargado, construye la ecuación y la evalúa.\n",
    "    Si se detecta \"==\" en la ecuación, se reemplaza por \"=\".\n",
    "\n",
    "    Args:\n",
    "        image_path (str): Ruta a la imagen a procesar.\n",
    "        model_to_use (torch.nn.Module): El modelo MLP cargado y en modo eval.\n",
    "        device (torch.device): Dispositivo ('cuda' o 'cpu').\n",
    "        target_mean (float): Media usada para normalizar ([0,1] scale).\n",
    "        target_std (float): Desviación estándar usada para normalizar ([0,1] scale).\n",
    "        idx_to_char_map (dict): Mapeo de índice de clase a carácter.\n",
    "\n",
    "    Returns:\n",
    "        str: La ecuación reconocida (con \"==\" reemplazado por \"=\").\n",
    "        float or str: El resultado de la evaluación o un mensaje de error.\n",
    "    \"\"\"\n",
    "    if idx_to_char_map is None:\n",
    "        print(\"Error interno: El mapeo idx_to_char_map no fue proporcionado a la función.\")\n",
    "        return \"Error Mapeo\", \"Error\"\n",
    "\n",
    "    try:\n",
    "        # --- 1. Cargar y Preprocesar Imagen (OpenCV) ---\n",
    "        img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if img is None:\n",
    "            print(f\"Error: No se pudo leer la imagen en {image_path}\")\n",
    "            return \"Error de lectura\", \"Error\"\n",
    "\n",
    "        img_inverted = ~img # Invertir para que el trazo sea blanco y el fondo negro\n",
    "        _, thresh = cv2.threshold(img_inverted, 127, 255, cv2.THRESH_BINARY) # Umbralizar\n",
    "        ctrs, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE) # Contornos\n",
    "\n",
    "        if not ctrs:\n",
    "            print(\"No se encontraron contornos en la imagen.\")\n",
    "            return \"Sin contornos\", \"Error\"\n",
    "\n",
    "        # Ordenar contornos por posición x\n",
    "        cnt = sorted(ctrs, key=lambda ctr: cv2.boundingRect(ctr)[0])\n",
    "        print(f\"Contornos encontrados inicialmente y ordenados: {len(cnt)}\")\n",
    "\n",
    "        # --- 2. Filtrar Contornos Anidados (Lógica del usuario) ---\n",
    "        rects = [cv2.boundingRect(c) for c in cnt]\n",
    "\n",
    "        bool_rect = []\n",
    "        for r_outer in rects:\n",
    "            l_inner = []\n",
    "            for rec_inner in rects:\n",
    "                flag = 0\n",
    "                if rec_inner != r_outer:\n",
    "                    x1_r, y1_r, w_r, h_r = r_outer\n",
    "                    x2_r, y2_r = x1_r + w_r, y1_r + h_r\n",
    "                    x1_rec, y1_rec, w_rec, h_rec = rec_inner\n",
    "                    x2_rec, y2_rec = x1_rec + w_rec, y1_rec + h_rec\n",
    "\n",
    "                    r_inside_rec = (x1_r >= x1_rec) and (y1_r >= y1_rec) and (x2_r <= x2_rec) and (y2_r <= y2_rec)\n",
    "                    rec_inside_r = (x1_rec >= x1_r) and (y1_rec >= y1_r) and (x2_rec <= x2_r) and (y2_rec <= y2_r)\n",
    "\n",
    "                    if r_inside_rec or rec_inside_r:\n",
    "                        flag = 1\n",
    "                l_inner.append(flag)\n",
    "            bool_rect.append(l_inner)\n",
    "\n",
    "        dump_rect = []\n",
    "        for i in range(len(cnt)):\n",
    "            for j in range(len(cnt)):\n",
    "                if bool_rect[i][j] == 1:\n",
    "                    area1 = rects[i][2] * rects[i][3]\n",
    "                    area2 = rects[j][2] * rects[j][3]\n",
    "                    if area1 <= area2:\n",
    "                        if list(rects[i]) not in dump_rect: dump_rect.append(list(rects[i]))\n",
    "                    else:\n",
    "                        if list(rects[j]) not in dump_rect: dump_rect.append(list(rects[j]))\n",
    "        \n",
    "        print(f\"Rectángulos marcados para eliminar (anidados/solapados): {len(dump_rect)}\")\n",
    "        final_rect_to_process = [r for r in rects if list(r) not in dump_rect]\n",
    "        final_rect_to_process.sort(key=lambda r: r[0]) # Asegurar orden por x\n",
    "        print(f\"Rectángulos finales después del filtrado: {len(final_rect_to_process)}\")\n",
    "\n",
    "        # --- 3. Procesar y Predecir cada Carácter Final ---\n",
    "        processed_chars_tensors = []\n",
    "        processed_chars_imgs = []\n",
    "\n",
    "        for r_idx, r_val in enumerate(final_rect_to_process):\n",
    "            x, y, w, h = r_val\n",
    "            \n",
    "            if w == 0 or h == 0: \n",
    "                print(f\"Advertencia: Rectángulo con dimensión cero {r_val}. Saltando.\")\n",
    "                continue\n",
    "\n",
    "            pad = 15 # Padding\n",
    "            y1_crop = max(0, y - pad); y2_crop = min(thresh.shape[0], y + h + pad)\n",
    "            x1_crop = max(0, x - pad); x2_crop = min(thresh.shape[1], x + w + pad)\n",
    "            im_crop = thresh[y1_crop:y2_crop, x1_crop:x2_crop]\n",
    "\n",
    "            if im_crop.size == 0:\n",
    "                print(f\"Advertencia: Recorte vacío para rect {r_val}. Saltando.\")\n",
    "                continue\n",
    "\n",
    "            im_resize = cv2.resize(im_crop, (28, 28), interpolation=cv2.INTER_AREA)\n",
    "            processed_chars_imgs.append(im_resize)\n",
    "\n",
    "            im_flattened = im_resize.reshape(784).astype(np.float32)\n",
    "            char_tensor = torch.tensor(im_flattened, dtype=torch.float32)\n",
    "\n",
    "            safe_std = target_std if target_std > 1e-6 else 1.0\n",
    "            char_tensor = (char_tensor / 255.0 - target_mean) / safe_std\n",
    "            char_tensor = char_tensor.unsqueeze(0).to(device)\n",
    "            processed_chars_tensors.append(char_tensor)\n",
    "\n",
    "        if not processed_chars_tensors:\n",
    "            print(\"No se pudieron procesar caracteres válidos después del filtrado.\")\n",
    "            return \"Sin caracteres válidos\", \"Error\"\n",
    "\n",
    "        # --- 4. Realizar Predicciones y Construir Ecuación ---\n",
    "        raw_equation = '' # Ecuación antes del post-procesamiento\n",
    "        confidences = []\n",
    "        predicted_indices = []\n",
    "\n",
    "        model_to_use.eval()\n",
    "        with torch.no_grad():\n",
    "            for char_tensor in processed_chars_tensors:\n",
    "                prediction_logits = model_to_use(char_tensor)\n",
    "                probabilities = F.softmax(prediction_logits, dim=1)\n",
    "                confidence, predicted_idx = torch.max(probabilities, 1)\n",
    "\n",
    "                predicted_idx_item = predicted_idx.item()\n",
    "                predicted_indices.append(predicted_idx_item)\n",
    "                confidences.append(confidence.item())\n",
    "\n",
    "                char = idx_to_char_map.get(predicted_idx_item, '?')\n",
    "                raw_equation += char # Construir la ecuación cruda\n",
    "                print(f\"  Predicción: Índice={predicted_idx_item}, Carácter='{char}', Confianza={confidence.item()*100:.1f}%\")\n",
    "\n",
    "        print(f\"\\nEcuación Cruda Reconocida: {raw_equation}\")\n",
    "\n",
    "        # --- NUEVO: Post-procesamiento para reemplazar \"==\" por \"=\" ---\n",
    "        equation = raw_equation.replace(\"==\", \"=\")\n",
    "        if \"==\" in raw_equation:\n",
    "            print(f\"Ecuación Corregida (reemplazando '==' por '='): {equation}\")\n",
    "        else:\n",
    "            print(f\"Ecuación Final (sin cambios de '=='): {equation}\")\n",
    "\n",
    "\n",
    "        # --- 5. Evaluar la Ecuación ---\n",
    "        result = \"No evaluable\"\n",
    "        try:\n",
    "            cleaned_equation_for_eval = equation.replace(' ', '')\n",
    "            \n",
    "            if re.fullmatch(r\"^[()]*([-+]?([0-9]*\\.?[0-9]+|[0-9]+\\.?[0-9]*)[()]*[+\\-*/]?)+$\", cleaned_equation_for_eval):\n",
    "                result = eval(cleaned_equation_for_eval)\n",
    "                print(f\"Resultado de la evaluación (expresión directa): {result}\")\n",
    "            elif cleaned_equation_for_eval.endswith('=') and \\\n",
    "                 re.fullmatch(r\"^[()]*([-+]?([0-9]*\\.?[0-9]+|[0-9]+\\.?[0-9]*)[()]*[+\\-*/]?)+$\", cleaned_equation_for_eval[:-1]):\n",
    "                expression_to_eval = cleaned_equation_for_eval[:-1]\n",
    "                print(f\"Intentando evaluar versión limpiada (sin '=' al final): {expression_to_eval}\")\n",
    "                result = eval(expression_to_eval)\n",
    "                print(f\"Resultado de la evaluación (limpiada): {result}\")\n",
    "            else:\n",
    "                result = \"Expresión no válida para eval()\"\n",
    "                print(f\"La expresión '{equation}' (limpiada: '{cleaned_equation_for_eval}') no parece válida para evaluar con las reglas actuales.\")\n",
    "\n",
    "        except ZeroDivisionError:\n",
    "            result = \"Error: División por cero\"\n",
    "            print(result)\n",
    "        except SyntaxError as e:\n",
    "            result = f\"Error de sintaxis en eval(): {e}\"\n",
    "            print(result)\n",
    "        except Exception as e:\n",
    "            result = f\"Error durante evaluación con eval(): {e}\"\n",
    "            print(result)\n",
    "\n",
    "        # --- 6. Visualización (Opcional) ---\n",
    "        # La visualización mostrará los caracteres tal como se enviaron al modelo (antes del reemplazo de \"==\")\n",
    "        try:\n",
    "            num_chars_to_display = len(processed_chars_imgs)\n",
    "            if num_chars_to_display > 0:\n",
    "                cols = min(num_chars_to_display, 8)\n",
    "                rows = (num_chars_to_display + cols - 1) // cols\n",
    "                fig, axs = plt.subplots(rows, cols, figsize=(cols * 1.5, rows * 2.5))\n",
    "                if rows == 1 and cols == 1:\n",
    "                    axs = np.array([axs]) \n",
    "                axs = axs.flatten()\n",
    "\n",
    "                for i in range(num_chars_to_display):\n",
    "                    axs[i].imshow(processed_chars_imgs[i], cmap='gray')\n",
    "                    # Mostrar el carácter predicho originalmente por el modelo para esta imagen\n",
    "                    original_pred_char_display = idx_to_char_map.get(predicted_indices[i], '?')\n",
    "                    conf_display = confidences[i] * 100\n",
    "                    axs[i].set_title(f\"'{original_pred_char_display}'\\n({conf_display:.0f}%)\")\n",
    "                    axs[i].axis('off')\n",
    "\n",
    "                for j in range(num_chars_to_display, len(axs)):\n",
    "                    axs[j].axis('off')\n",
    "\n",
    "                # El título de la figura mostrará la ecuación final (posiblemente corregida)\n",
    "                fig.suptitle(f\"Predicciones (Pre-corrección '==')\\nEcuación Final: {equation}\\nResultado: {result}\", fontsize=12)\n",
    "                plt.tight_layout(rect=[0, 0.03, 1, 0.92])\n",
    "                plt.show()\n",
    "        except Exception as e:\n",
    "            print(f\"No se pudo mostrar la visualización de caracteres: {e}\")\n",
    "\n",
    "        return equation, result # Devuelve la ecuación posiblemente corregida\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error general en predict_equation_from_image: {e}\")\n",
    "        return \"Error general\", \"Error\"\n",
    "\n"
   ],
   "id": "464e4bea4e34f756",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# =============================================================================\n",
    "# 11. Prueba de funcionamiento\n",
    "# ============================================================================="
   ],
   "id": "6da1dc24bf9911f7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Descripción:\n",
    "Esta sección ejecuta una prueba utilizando la función `predict_equation_from_image` con una imagen de ejemplo (especificada en `test_equation_image_path`). Muestra la ecuación reconocida, el resultado de su evaluación y la visualización de los caracteres procesados. Es el punto final para probar la funcionalidad completa del sistema.\n"
   ],
   "id": "f2973f02aa224e18"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T18:19:16.080967Z",
     "start_time": "2025-05-13T18:19:15.868920Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Ejecución de la prueba con una imagen ---\n",
    "if loaded_model is not None: # Solo si el modelo se cargó correctamente\n",
    "    if 'idx_to_char' in globals():\n",
    "        print(\"\\n--- Probando con una imagen que contiene una ecuación ---\")\n",
    "\n",
    "        # !!! IMPORTANTE: Cambia esta ruta a la de tu imagen !!!\n",
    "        test_equation_image_path = \"C:/Users/Wisp8/Desktop/Numeros/Ec2.png\" \n",
    "\n",
    "        if not os.path.exists(test_equation_image_path):\n",
    "            print(f\"Error: La imagen de prueba no existe en: {test_equation_image_path}\")\n",
    "            print(\"Por favor, crea una imagen (ej. 'Data/Prueba.png') con una ecuación simple (ej. 12+5) o cambia la ruta.\")\n",
    "        else:\n",
    "            # Llamar a la nueva función de predicción\n",
    "            recognized_equation, evaluation_result = predict_equation_from_image(\n",
    "                test_equation_image_path,\n",
    "                loaded_model,\n",
    "                device,\n",
    "                mean, # Media global calculada en sección 3\n",
    "                std,  # Std global calculada en sección 3\n",
    "                idx_to_char \n",
    "            )\n",
    "\n",
    "            print(f\"\\n--- Resumen Final ---\")\n",
    "            print(f\"Imagen Procesada: {test_equation_image_path}\")\n",
    "            print(f\"Ecuación Reconocida: {recognized_equation}\")\n",
    "            print(f\"Resultado Evaluación: {evaluation_result}\")\n",
    "    else:\n",
    "        # Mensaje de error si idx_to_char no está definido\n",
    "        print(\"\\nError Crítico: La variable 'idx_to_char' no está definida en el scope global.\")\n",
    "        print(\"Asegúrate de que la Sección 2 (donde se define idx_to_char) se haya ejecutado correctamente antes de esta sección.\")\n",
    "\n",
    "else:\n",
    "    print(\"\\nNo se puede probar con una imagen porque el modelo no se cargó correctamente.\")"
   ],
   "id": "91e1f217e9b3e076",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Probando con una imagen que contiene una ecuación ---\n",
      "Contornos encontrados inicialmente y ordenados: 3\n",
      "Rectángulos marcados para eliminar (anidados/solapados): 0\n",
      "Rectángulos finales después del filtrado: 3\n",
      "  Predicción: Índice=5, Carácter='5', Confianza=99.3%\n",
      "  Predicción: Índice=15, Carácter='.', Confianza=98.6%\n",
      "  Predicción: Índice=7, Carácter='7', Confianza=99.5%\n",
      "\n",
      "Ecuación Cruda Reconocida: 5.7\n",
      "Ecuación Final (sin cambios de '=='): 5.7\n",
      "Resultado de la evaluación (expresión directa): 5.7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 450x250 with 3 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Resumen Final ---\n",
      "Imagen Procesada: C:/Users/Wisp8/Desktop/Numeros/Ec2.png\n",
      "Ecuación Reconocida: 5.7\n",
      "Resultado Evaluación: 5.7\n"
     ]
    }
   ],
   "execution_count": 22
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
