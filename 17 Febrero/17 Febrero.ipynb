{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Extreme seeking",
   "id": "d323b950b6ec7025"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Given the function:\n",
    " $$f(x)=3x^2+2x+1$$\n",
    "Find the value of ùë• that minimizes $f(x)$ using all the extreme seeking algorithms "
   ],
   "id": "76ae70849d06da50"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Gradient Descent",
   "id": "d1274bc2c132ccf6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-17T16:18:37.680240Z",
     "start_time": "2025-02-17T16:18:37.407280Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "def gradient_descent(gradient, start, learning_rate=0.1, n_iter=100, tol=1e-6):\n",
    "    \"\"\"\n",
    "    Perform Gradient Descent to minimize a function.\n",
    "\n",
    "    Parameters:\n",
    "        gradient (function): The gradient function of the objective function.\n",
    "        start (float): The initial point to start the optimization.\n",
    "        learning_rate (float): The step size for each iteration.\n",
    "        n_iter (int): The maximum number of iterations.\n",
    "        tol (float): The tolerance for stopping criteria.\n",
    "\n",
    "    Returns:\n",
    "        float: The optimized value of x.\n",
    "    \"\"\"\n",
    "    x = start  # Initialize the starting point\n",
    "    for _ in range(n_iter):\n",
    "        grad = gradient(x)  # Compute the gradient at the current point\n",
    "        if np.abs(grad) < tol:  # Check if the gradient is close to zero (stopping condition)\n",
    "            break\n",
    "        x = x - learning_rate * grad  # Update x using the gradient\n",
    "    return x\n",
    "\n",
    "# Define the objective function and its gradient\n",
    "def f(x):\n",
    "    return 3*(x**2)+2*x+1  \n",
    "\n",
    "def grad_f(x):\n",
    "    return 6 * x + 2\n",
    "\n",
    "# Run Gradient Descent\n",
    "start = 0.0  # Initial point\n",
    "solution = gradient_descent(grad_f, start)\n",
    "print(\"Solution found:\", solution)"
   ],
   "id": "7ba03c6324446845",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution found: -0.3333331901677568\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Newton's method",
   "id": "ba0205fcd1808d20"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-17T16:30:17.872780Z",
     "start_time": "2025-02-17T16:30:17.856943Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def NewtonMethod(func, firstD, secondD, start, n_iter=100, tol=1e-6):\n",
    "    \n",
    "    x = start\n",
    "    #Si le das al valor desde un inciio que se quede ah√≠-\n",
    "    if np.abs(func(x)) < tol:\n",
    "        return x\n",
    "    \n",
    "    #Si no, que siga el proceso\n",
    "    for _ in range(n_iter):\n",
    "        fprimEval = firstD(x)\n",
    "        fsecnEval = secondD(x)\n",
    "        x = x - (fprimEval/fsecnEval)\n",
    "        if np.abs(func(x)) < tol:  \n",
    "            break\n",
    "    return x\n",
    "\n",
    "def primD(x):\n",
    "    return 6 * x + 2\n",
    "\n",
    "def secD(x):\n",
    "    return 6\n",
    "\n",
    "# Run Gradient Descent\n",
    "start = 0.0  # Initial point\n",
    "solution = NewtonMethod(f, primD, secD, start)\n",
    "print(\"Solution found:\", solution)"
   ],
   "id": "1c839865c9984ead",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution found: -0.3333333333333333\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### PSO Algorithm",
   "id": "1e8a571c67b7c36e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-17T16:33:17.178350Z",
     "start_time": "2025-02-17T16:33:17.161118Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def pso(f, n_particles=10, n_iter=100, w=0.5, c1=1.5, c2=1.5):\n",
    "\n",
    "    particles = [random.uniform(-10, 10) for _ in range(n_particles)]  # Initialize particles\n",
    "    velocities = [random.uniform(-1, 1) for _ in range(n_particles)]  # Initialize velocities\n",
    "    best_positions = particles.copy()  # Initialize best positions\n",
    "    best_fitness = [f(p) for p in particles]  # Compute initial fitness\n",
    "    global_best = min(best_fitness)  # Find the global best fitness\n",
    "    global_best_position = particles[best_fitness.index(global_best)]  # Find the global best position\n",
    "\n",
    "    for _ in range(n_iter):\n",
    "        for i in range(n_particles):\n",
    "            r1, r2 = random.random(), random.random()\n",
    "            # Update velocity\n",
    "            velocities[i] = (w * velocities[i] +\n",
    "                             c1 * r1 * (best_positions[i] - particles[i]) +\n",
    "                             c2 * r2 * (global_best_position - particles[i]))\n",
    "            # Update position\n",
    "            particles[i] += velocities[i]\n",
    "            # Update fitness\n",
    "            fitness = f(particles[i])\n",
    "            if fitness < best_fitness[i]:\n",
    "                best_fitness[i] = fitness\n",
    "                best_positions[i] = particles[i]\n",
    "                if fitness < global_best:\n",
    "                    global_best = fitness\n",
    "                    global_best_position = particles[i]\n",
    "    return global_best_position\n",
    "\n",
    "solution = pso(f)\n",
    "print(\"Solution found:\", solution)"
   ],
   "id": "a6581bb8da7ef4c5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution found: -0.333333332940419\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Simulated Annealing",
   "id": "e1eb79ce8c1feead"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-17T16:34:25.607905Z",
     "start_time": "2025-02-17T16:34:25.589836Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import random\n",
    "import math\n",
    "\n",
    "def simulated_annealing(f, start, temp=1000, cooling_rate=0.99, n_iter=1000):\n",
    "    current = start  # Initialize the current solution\n",
    "    for i in range(n_iter):\n",
    "        T = temp * (cooling_rate ** i)  # Update temperature\n",
    "        neighbor = current + random.uniform(-1, 1)  # Generate a neighbor solution\n",
    "        delta = f(neighbor) - f(current)  # Compute the difference in fitness\n",
    "        if delta < 0 or random.random() < math.exp(-delta / T):  # Accept the neighbor with a probability\n",
    "            current = neighbor\n",
    "    return current\n",
    "\n",
    "start = 0  # Initial point\n",
    "solution = simulated_annealing(f, start)\n",
    "print(\"Solution found:\", solution)"
   ],
   "id": "6ba277ab7ac9d282",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution found: -0.36425325272846343\n"
     ]
    }
   ],
   "execution_count": 5
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
